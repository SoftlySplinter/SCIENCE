# SE33010 - Formal Methods in Software Engineering

Fred Long (fwl). 

The use of mathematical formal methods in software specification and techniques for producing reliable software.

**Reminder:** Fred has a good lecturing style :)

You will need to put effort in to succeed. Not all mathematics (but there is a fair amount).

Links on blackboard to books (both out of print).


### Assessment

* 80% Exam
* 10% Written Assignment
* 10% Written Assignment

Also $\approx 3$ un-assessed worksheets in workshops.


### Why do we need formal methods?

Bugs are common in software.

Legal requirement to report vulnerabilities (vulnerabilities are a special class of bug).

> "If debugging is the process of taking out bugs, programming must be the process of putting them in."

Cannot prove the absence of bugs by testing software. Need to be able to prove there are no bugs in the software $\rightarrow$ prove the software is correct. Mathematical techniques can begin to do this.

Few example of where this has been done successfully:

* Metro lines in Paris (14) Oct. 1998 has an automatic train control system was developed on time, in budget and was proved to be 100% correct using formal proof.
* A real time air-traffic control system used VDM, developed for London airports. Productivity of developers: 13 lines per person per day compared to 7. Wasn't proved to be correct - 35% reduction in defects. Industry standard: 1 defect per 1000 lines of code.
* BMW/Rolls Royce test facility used Z notation for certification testing of the electronic control system.
* NASA international space system fault detection system, irregularities discovered early in development using formal methods.
* IEEE reporting on experience from a student group project. Two classes of groups of students, one using formal development, one using traditional development (small groups, 2 students per group). 45.5% of traditional groups passed testing, 100% of formal groups passed testing.


## Introduction to Logic

### Formalisation of Software Development

1. User's ideas
2. Requirements Specification
3. System specification
4. Programs
5. Executable Machine Code

Last step is often automated. Idea of formal methods is to move the automation up (use tools to automatically generate code).

To do this the specification must be amenable to processing (cannot be a natural language).

Need to use a "formal" specification language.

There is some research into introducing formal notations for requirement specification, but of course (accept in very few examples) you're never going to be able to completely automate this process.

Ideas are very difficult to formalise.

This module focuses on a formal definition for a system specification.

Compilers can be completely automated from requirements.


### Specification

A specification should be:

* Concise
* Complete
* Consistent

May go through several stages and may come in a number of pieces.

It is important to maintain consistency between stages of specification, traditional methods of software development make this difficult. This is because of the large, natural language nature of the traditional specification (relies on humans to ensure consistency).

Mathematical methods of specification can help with this. This definitely addresses the issue of being concise (downside on people not being familiar with the notion). Big advantage is the use of software tools to analyse the specification for consistency, may be able to have a check for completeness. Some chance of being able to check for missing elements of the specification.



### Advantages of Formal Specification

* Makes you think. Natural languages allow for "sloppiness". Constrained about things like integer values, etc. This is surprisingly important and is often overlooked.
* Unambiguous language. Natural language is very context sensitive.
* May be autonomous. From formal specification it may be possible to generate code, for example. Can lead to inefficient code, this might be used as a prototype rather than end product.
* Automated test data. Very likely to pick up boundary cases where software is likely to go wrong.
* Can be proved to be correct rather than tested. Testing is still important and does a different job. This might make unit testing redundant.
* Errors detected earlier.
* Adapt to changing requirements more reliably. Can also introduce metrics of how it will affect the system.
* Very good for rapid prototyping.

### Disadvantages of Formal Specification

* Specification difficult to communicate to users. Difficult to get "sign-off".
* Highly specialised workforce.
* May sacrifice efficiency if used blindly. If applied properly it should be just as efficient.
* May need sophisticated (*read: expensive*) tools.
* May need additional computing facilities (theorem provers ran on specialised hardware). Lately this is less of a problem, but most tools are very resource intensive.


###Note on terminology

Sometimes "formal methods" may be via the use of documentation and/or coding standards. In this course we are talking about a Mathematically formal specification.


### Approaches to a Formal Specification

Two approaches

* Algebraic (axiomatic)
* Model-based (operational)

An algebraic specification defines a mathematical object in terms of relations among the operations defined over the object. In many ways this is more abstract

A model-based approach is an explicit system model constructed from abstract or concrete primitives (think of this as another programming language).

Focus on model-based specifications, particularly VDN.


###Example of Algebraic Specification

Example of a boolean type.

```
INITIAL
  boolean

SORT
  bool

CONSTANTS
  true   : bool
  false  : bool

OPERATIONS
  not _	     : bool -> bool
  _ or _     : bool, bool -> bool
  _ and _    : bool, bool -> bool
  _ impl _   : bool, bool -> bool
  _ equiv _  : bool, bool -> bool

EQUATIONS
  not(not(A))   = A
  A or (B or C) = (A or B) or C
  A or B        = B or A
  A or true     = true
  A or false    = A
  A and B       = not(not(A) or not(b))
  A impl B      = not(A) or B
  A equiv B     = (A impl B) and (B impl A)
END
```

`INITIAL` means that there are no values or relations other than those which can be deduced from the given ones, for example one can deduce that `A and B = B and A`, buy not `true = false`.

The mathematical branch of *category theory* is needed to reason about such specifications.


```
INITIAL
  lists (elem with {_ eq _ : elem,elem -> bool; undef : -> elem})

USES
  boolean

SORT
  list

CONSTANTS
  empty  : list
  undef  : list

OPERATIONS
  _ . _             : elem,list -> list
  first _           : list -> elem
  rest _            : list -> list
  is-undef _        : list -> bool
  _ is-member-of _  : elem,list -> bool
  _ eq _            : list,list -> bool
  at-end _          : list -> bool

EQUATIONS
  first(empty)         = undef
  first(undef)         = undef
  first(A.B)           = A
  rest(empty)          = undef
  rest(undef)          = undef
  rest(A.B)            = B
  is-undef(empty)      = false
  is-undef(undef)      = true
  is-undef(A.B)        = false
  E is-member-of undef = false
  E is-member-of empty = false
  E is-member-of (A.B) = (E eq A) or (E is-member-of B)
  (A.B) eq (C.D)       = (A eq C) and (B eq D)
  empty eq empty       = true
  (A.B) eq empty       = false
  A eq B               = B eq A
  at-end(empty)        = true
  at-end(undef)        = false
  at-end(A.B)          = false
END
```


## The Vienna Development Method

Early 1960's, IBM Vienna Laboratory, working on the formal definition PL/1 (in cooperation with IBM UK Labs. Hursley).

Metalanguage then known as VDL (Vienna Definition Language).

1974, Formal description of PL/1, notation used became known as *META-VI*.

Key developers:

* Dines Bjørner
* Cliff D Jones

The notation evolved with time, essential an "English School" and a "Danish School".

Later developments:

* STC VDM Reference Language
* Rigorous Approach to Industrial Software Engineering (RAISE) Specification Language (RSL)

Then standardised into:

* BSI VDM Specification Language (VSL)
* International Standards ISO/IEC 13817-1, December 1996: "Vienna Development Methods - Specification Language - Part I: Base Language"


### VDM as a Development Method

Start with a (very) abstract specification and build an implementation from it.

Uses *data reification* and *program decomposition*, both of which are accompanied by *proof obligations*

Specification defines Abstract data types and are reifoicated to data structures in the implementation.

Specification also defines operations are decomposed to algorithms.


### Specification in VDM


### Functions

Uses implicit declaration.

Has:

* Signature, the name of the function
* Pre-condition, must be true on entering the function.
* Post-condition, must be true on exiting the function

Example:


$$ \text{max}(i:Z,j:Z)r:Z $$
$$ \text{pre } true $$
$$ \text{post } (r=i \lor r=j) \land i \le r \lor j \le r $$

Can refer to pre- or post-condition out of context, we can use the notation: `pre-max` and `post-max`.

So a specification with the signature:

$$ f(p:Tp)r:Tr $$

Corresponds to a function

$$ f \rightarrow Tp, Tr $$


### Advantages of Implicit Specification

* Direct statement of multiple properties of interest to the user.
* Characterising a set of possible results by a post-condition.
* Explicit pre-condition.
* Less commitment to a specific algorithm.
* A direct naming of the result.


### Example of implicit specification

$$ \text{sqrt}(x:R)r:R $$
$$ \text{pre } x \ge 0 $$
$$ \text{post } abs(x-r^2) \lt 10^{-8} $$

Now, suppose we want to find the forth root function, we might try to use `sqrt` twice.

$$ y = \text{sqrt}(x) $$
$$ z = \text{sqrt}(y) $$

For this to work wee need

$$ \text{post-S1} \Rightarrow \text{pre-S2} $$

i.e.

$$ abs(x-y^2) \lt 10 ^ {-8} \Rightarrow y \ge 0 $$

Clearly, this is not true because a negative $y$ could satisfy the left-hand side of the implication, but not the right.


### Formal Logic

A **formal language** is:

* A set of symbols - the **alphabet** of the language, and
* A set of rules to specify how the symbols together - the **syntax**.

An acceptable string of symbols is a **well formed formular (wff)** of that language.

The **sematics** of a formal language is specified by attaching a meaning to each wff admitted by the syntax.

###Propositional Logic

Uses truth-valued quantities.
$$ A, B, ..., Z $$

Normal brackets $($ and $)$.

* $\neg$ negation (not), unary
* $\land$ conjunction (and), binary
* $\lor$ disjunction (or), binary
* $\Rightarrow$ implication (implies), binary
* $\Leftrightarrow$ equivalence (is equivalent to), binary

The syntax is simply:

```
proposition ::= letter
              | ¬proposition
              | proposition ∧ proposition
              | proposition V proposition
              | proposition -> proposition
              | proposition <-> proposition
              | (proposition)
```

Examples of valid wffs:

```
A,(A),¬A ∧ B
```

Precedence defined by the order. Note this is strict as no two operators have the same precedence.


####Implication

$$A \Rightarrow B$$

Consider:

$$ i = 2 \Rightarrow i^2 = 4 $$

When $i = 2$, both sides will be true. Resolves to true.

When $i = -2$ the left hand side will evaluate to false, the other to true. Resolves to true.

When $i = 1$ both sides are false, which resolves the implication to true.

For the final entry, consider $i=1 \Rightarrow i^2 = 4$

When $i = 1$ the left-hand side is true, the other false. Resolves to false.


$$ A \Rightarrow B \equiv \neg A \lor B $$


###Semantic Reasoning

Semantic reasoning leads to the idea of validity denoted by the double turnstile symbol $\models$

Let $P$ be a finite list of propositions - the *premises*. 

If, whenever all propositions of $P$ are true then the proposition $W$ is true, we say that $P$ provides the validity of $W$, written $P \models W$

If $P$ is empty then $\models W$ means that $W$ is always true and we say that $W$ is a tautology.

Propositions $P$ and $Q$ are logically equicalent if $\models P \Leftrightarrow Q$ (sometimes written $P \equiv Q$)


###Syntactic Reasoning/Formal Proof

In formal logic we are concerned with the syntatic derivations or **formal proofs**, rather than the meanings.

That is:

* We have a set of **axioms** - wffs which can be written without reference to any other wff in the language.
* A set of **inference rules** - rule which describe how wffs can be produces as *immediate consequences* of other wffs in the language.

A **derivation** or **formal proof** of the wff $W$ form a given set of wffs $P$ (the *premises*) is a finite sequence of wffs, each of which is either:

1. An axiom
2. A premise
3. An immediate consequence of one or more preceding wffs (as determined by the inference rules)

If there is such a derivation of $W$ from $P$ we write $P \vdash W$.

$\vdash$ is the single turnstyle, or syntactic turnstyle.

Applying formal proofs to propositional logic gives us the **propositional calculus**.

There are many choices of deductive system for the propositional calculus, the system outlined below is called a *Gentzen Natural Deductive System*.

####Some Inference Rules

$$\frac{A,B}{A \land B} \text{ and } \frac{A,B}{B \land A}\text{  }\land\text{-Introduction}$$

$$\frac{A \land B}{A} \text{ and } \frac{A \land B}{B} \text{  }\land\text{-Elimination}$$

$$\frac{A}{A \lor B} \text{ and } \frac{A}{B \lor A} \text{  }\lor\text{-Introduction}$$

etc.

####An Example

Show that $P \land Q \vdash P \lor Q$

Proof:


-  ----------  ------------------------
1  $P \land Q$  premise
2  $P$         1 by $\land$-Elimination
3  $P \lor Q$  2 by $\lor$-Introduction
-  ----------  ------------------------

Q.E.D.


####Another example

Show that $P,P \Rightarrow Q, Q\Leftrightarrow R \vdash Q \land R$


-  ---------------------------  -----------------------------------------
1  $P$                          premise
2  $P \Rightarrow Q$            premise
3  $Q \Leftrightarrow R$  premise
4  $Q$                          1,2 by $\Rightarrow$-Elimination
5  $Q \Rightarrow R$            3 by $\Leftrightarrow$-Elminiation
6  $R$                          4,5 by $\Rightarrow$-Elimination
7  $Q \land R$                   4,6 by $\land$-Introduction
-  ---------------------------  -----------------------------------------

Q.E.D.


### Consistency and Completeness

The propositional calculus is boy **consistent** and **complete**.

**Consistency** If $P$ is any finite set of propositions and $W$ is a proposition such that $P \vdash W$ then $P \models W$

That is, anything which can be formally proved can be show... (*A: I give up see the slides*).


### Application

Propositional logic can be applied to model the behaviour of digital electronic circuits. Used to reason about the behaviour of circuits, the decidability theorem implies that finite algorithms can be used to create the circuit.


### Predicate Logic

We want to use logic to reason about the correctness of computer programs. To do this we need a language which is more powerful than the propositional logic. We introduce truth valued functions: *predicates*:

$$positive(counter)$$

Can have more than one argument:

$$bigger\_than(counter,total)$$

More conveniently, we write this in *infix* form as:

$$counter \lt total$$

The alphabet of the predicate is that for propositional logic, extended by lower case letters, the symbols $\forall$ $\exists$ $\bullet$, and arbitary strings of letters (upper or lower case).

$\forall x$ is read "for all $x$"

$\exists x$ is read "there exists $x$"


## VDM

###Built in Sets

**B** = booleans

**N** = Unsigned integers starting at 0

$\text{N}_1$ = Unsigned integers starting at 1

**Z** = Signed integers

###Some example notation

$$ \_ + \_ : Z \times Z \rightarrow Z $$

$$ \_ mod \_ : N \times N_1 \rightarrow B $$


### Proof Obligation for Functions

Suppose we have an implicit specification:

$$f(p:T_p)r:T_r$$

`pre pre-f(p)`

`post post-f(p,r)`

$$ f:T_P \rightarrow T_r$$



Suppose we have to define multiplication:

$$ multp(i,j)  $$

```
  if   i = 0
  then 0
  else if   is-even(i)
    then 2 * multp(i/2, j)
    else j + multp(i-1, j)
```

Then the proof obligation becomes:

$$ \forall i,j \in \text{N} \bullet multp(i,j) \in \text{N} \land multp(i,j) = i \times j $$


### Partial Functions

Consider:

$$ subp(i:\text{N}, j:\text{N})r:\text{N} $$

```
pre j <= i
post r + j = i
```

An explicit definition of $subp$ will generate the following proof obligation:

$$ \forall i,j:\text{N} \bullet \text{pre} - subp (i,j) \Rightarrow subp(i,j) \in \text{N} \land \text{post} - subp(i,j) $$

i.e.

$$ \forall i,j:\text{N} \bullet j \le i \Rightarrow subp(i,j) \in \text{N} \land subp(i,j) + i = j$$

Can't complete this evaluation; when $j$ is bigger than $i$ this equation is undefined.

However, using **Logic of Partial Functions** (LPF):

1. If $j \le i$ the implication becomes $\text{T} \Rightarrow \text{T} \land \text{T}$ which evaluates to **T**.
2. If $j \gt i$ the implication becomes $\text{F} \Rightarrow \text{* } \land \text{ *}$ which evaluates to **T**.

The "Law of the Excluded Middle" ($\vdash P \lor \neg P$) clearly does not hold in LPF.

This is, in fact, a virtue with partially defined functions, for example, there is no reason for:

$$ \frac{2}{0} = 1 \lor \frac{2}{0} \ne 1 $$

However, we do get useful results like:

$$\forall n \bullet n \in \text{Z} \Rightarrow n = 0 \lor \frac{n}{n} = 1 $$

Another rule which doesn't hold in LPF is $\vdash P \Rightarrow P$.


### Domain of Interest

The domain of interest can now be defined rigorously by specifigying over which set the bound variables range.

For example

$$ \exists x \bullet x \gt 4$$

Can be more precisely specifed by

$$ \exists x \bullet x \in \text{N} \land x \gt 4 $$

The expression still has meaning when $x \gt 4$ is undefined.

So, in future, we will always quantify over some set and we introduce an avvreviated notation:

$$ \forall x \in S \bullet P(x) \text{for} \forall x \bullet \in S \Rightarrow P(x) $$


### States and Operations

Functions may not have side effects, instead we have **states** and **operations** on the states.

Example:

```
state Register as
    reg: N
end

LOAD(i:n)
ext wr reg:N
post reg = i
```

The exterior clause (`ext`) specifies which parts of the state can be accessed by the operation.

* `rd` means read access
* `wr` means write access (implies read access)

Operation labels landitalised by convention.

Hooked variables denote the value of that variable prior to the execution of the operation.

Returning works like:

```
SHOW()r:N
ext rd reg:N
post r = reg
```

Can also have `pre-OP` and `post-OP`.


### Data Types

Predefined sets: **B**, **N**, **N**1, **Z**, **Q**, **R**.

For a set *X*, *X-set* is the set of all finite subsets of *X*.

e.g.: **B**-set = {{},{true},{false},{true,false}}

A useful abbreviation for sets of integers is:

$$\{i,...,j\}=\{ k \in Z \ldots$$

VDM-SL admits a lot of useful set operations.

Type of `To Be Defined` is allowed and just means the type is defined somewhere else.

**Just a note:** no concurrency in VDM so you don't have to worry about locking.

###Composite Type

The general form of a composite type definition is:

```
Name ::
  s1 : T1
  s2 : T2
  .
  .
  .
  sn : Tn
```

This type has associated with it the constructor:

```
mk-Nam : T1 x T2 x ... x Tn -> Name
```

And selector functions:

```
s1 : Name -> T1
s2 : Name -> T2
.
.
.
sn : Name -> Tn
```

Example:

```
Date ::
  day : {1,...,366}
  year : {1901,...,2099}
```

Automatically gives us these functions:

```
mk-Date({1,...,366} x {1901,...,2099} -> Date
day : Date -> {1,.366}
year : Date -> {1901, 2099}
```

For example: `mk-date{45,2003}`

There is the problem of leap years in this example. So we might want a function `valid-Date : Date -> B` to determine whether a date is actually valid.

```
valid-Date(dt) ? is-leapyear(year(dt)) V day(dt) <= 365

is-leapyear(i) ? i mod 4 = 0
```

Alternatively:

```
valid-Date(dt) ?
  let mk-Date(d,y) = dt
  in is-leapyear(y) V d <= 365
```

**Note:** Because of the restricted year range our definition of leap year works.

Data type **invariants** can be added to composite types using the construction:

```
Date ::
  day : {1,...,366}
  year : {1901,...,2099}
where
  inv-Date(mk-Date(d,y)) ? is-leapyear(y) V d <= 365
```

Now only valid dates will be allowed on the constructor.

####Optional Fields

Optional fields are allowed in composite types, denoted by `[...]`, and an omitted field is denoted by `nil`:

```
Record ::
  day : {1,...,366}
  year : {1901,...,2099}
  valid : [ERROR]
```

Useful for recursive data types.

###Recursive Data Definitions

```
List = [Listelt]
Listelt ::
  hd : N
  tl : List

nil in List
mk-Listelt(3,nil) in List
mk-Listelt(1,mk-Listelt(2,mk-Listelt(3,nil))) in List

lsum : List -> N
lsum(l) ?
  cases l:
    nil -> 0
    mk-Listelt(hd,tl) -> hd + lsum(tl)
  end
```

####Binary Search Tree Example

```
Tree = [Node]
Node ::
  left : Tree
  value : N
  right : Tree
where
  inv-Node(mk-Node(left,value,right)) ?
    (forall(lv) in values(left) assert lv < value) and (forall(rv) in values(right) assert value < rv)
values : Tree -> N-set
values(t) ?
  cases t of
    nil -> {}
    mk-Node(left,value,right) -> values(left) union {value} union values(right)
```


### Maps

A **map** is similar to a function defined on a finite set, except that the argument:result pairs are given explicitly.

e.g.: $\left\{{a_1 \mapsto r_1, a_2 \mapsto r_2,\ldots ,a_n \mapsto r_n}\right\}$

$$\left\{{x \mapsto f(x)|P(x)}\right\}$$

Denoted by

$$ X \rightarrow^{m} Y $$

###Map Overriding

$$m_1 \dagger m_2$$

$m_2$ overrides elements in $m_1$. If an element in exists in both $m_1$ and $m_2$ then the return from $m_2$ is used, otherwise it's just the union of the two maps.


### Sequences

Given a type $X$, we can have *sequences* of elements of $X$.

The types of such sequences is denoted by $X*$

Sequences are denoted by:

$$\left[ a,b,c \right]$$

Where:

$$ a,b,c, \in X $$


###Operations

------------------------ ----------------------------- --------------------
$hd\_$                   $X* \rightarrow X$            head (first element)
$tl\_$                   $X* \rightarrow X*$           tail
$len\_$                  $X* \rightarrow N$            length
$elems\_$                $X* \rightarrow X\text{-set}$ set of elements
$\_(\_)$                 $X \times N_1 \rightarrow X$  element selection
$\_ \curvearrowright \_$ 
------------------------ ----------------------------- --------------------


## VDM as a Development Method

When using VDM, we start with a (very) abstract specification and, in a number of steps, develop this into an implementation

Each step involves:

* Data Reification
* Operation Decomposition

Data reification develops the abstract data types into more concrete data structures.

Operation decomposition develops the abstract implicit specification of functions and operations into algorithms which can be put into code.


### Data Reification

Data reification develops the abstract data types into more concrete data structures.

There may be several steps before an implementation is reached.

Each step involves:

* Given an abstract data representation $ABS$, find a new representation $REP$.
* Find a **retrieve function** that relates $ABS$ to $REP$: $retr : REP \rightarrow ABS$.
* Prove that $REP$ is **adequet** to represent $ABS$. *i.e.* prove $\forall a \in ABS \bullet \exists r \in REP  \bullet a = retr(r)$
* Reqrite the functions and operations in terms of the new representation
* Prove that the new functions and operations preserve any data-type invariants of the new representation
* Prove that the new functions and operations model those of the original specifications; this involves two rules:

###Doman Rule

$$ \forall r \in REP \bullet \text{pre-}OPA(retr(r)) \Rightarrow \text{pre-}OPR(r) $$

###Modelling Rule

$$ \forall r', r \in REP \bullet \text{pre-}OPA(retr(r')) \land \text{post-}OPA(r', r) \Rightarrow \text{post-}OPA(retr(r'),retr(r)) $$

$r'$ is the initial state before the operation was run.


### Implementation of Data Reification

Implementation in a traditional programming language (e.g.: Java) suggests having a sequence of objects.

So, the first data reification step is to represent the data in terms of sequences.

We must not allow repetitions in our sequences because the same employee cannot occur twice; hence, we require an invariant on our new data type.

However, the set $\left\{{p,q}\right\}$ could be represented by $\left[{p,q}\right]$ or by $\left[{q,p}\right]$

A completely rigorous development down to programming language, then the programming language has to be formally specified.


## Proving Correctness

* *Validation* - Implementation which does the right thing.
* *Verification* - Implementation meets the specification.


### Correctness Proof

A correctness proof is the predicate calculus used in computing for the specification of computer programs and then reasoning about these specifications. The introduction of a formal language for the specification helps to make this more rigorous and may help to point out potential ambiguities in a system.

By using a formal (mathematical) notation the results can be **proved** about the specification.

If a formal proof is used correctly throughout the development process (including the use of a formally defined programming language) then it is possible to produce a formally proved implementation. That is, an implementation which is proved to meet its specification.

The predicate language can be used as a functional specification language, done by providing two formulae:

* Pre-condition,
* Post-condition.

As the name suggests, the pre-condition specifies the input restrictions and the post-condition specifies how the result should be related to the input.

If $S$ is the section of code to be specified this is written as:

$$\{\mathcal{I}\}\mathit{S}\{\mathcal{O}\}$$

###Example

$\{a \ne 0 \land b^2 > 4ac\}$

```
    double : d, x1, x2;
    d = Math.sqrt(b * b - 4 * a * c);
    x1 = (-b + d) / (2 * a);
    x2 = (-b - d) / (2 * a);
```

$\{x1 \ne x2 \land a(x1)^2 + b(x1) + c = 0 \land a(x2)^2 + b(x2) + c = 0\}$

The proof is as follows:

* $b^2 > 4ac$ ensures $d$ is defined and $d \ne 0$.
* $a \ne 0$ ensures $x1$ and $x2$ are both defined.
* $d \ne 0$ implies $x1 \ne x2$.
* To check $x1, x2$ satisfy $ax^2 + bx + c = 0$ is a matter of routine algebra.

This is a bad example as the mathematical verification relies on real numbers, clearly an implementation will only use an approximation to real number (floating point problems).

A mismatch between mathematical arithmetic and machine arithmetic is a problem within formal methods which does not seem to have been fully addressed. There are fewer problems with integer arithmetic, where the machine arithmetic is exact, but the limited range of machine integers and integer overflow may still cause problems.

There are formally defined (IEEE) standards for machine arithmetic but formal methods continue to use mathematical arithmetic.

The formula $\{\mathcal{I}\}S\{\mathcal{O}\}$ means that $\mathcal{I}$ is satisfied immediately prior to the execution of $S$ and $\mathcal{O}$ must be immediately satisfied by $S$, assuming $S$ halts.

Proving this result is called **partial verification**; $S$ is **partially correct** with respect to $\mathcal{I}$ and $\mathcal{O}$.

If it can be proved that $\mathcal{I}$ implies that $S$ will always halt, then this is called **total verification**; $S$ is **totally correct** with respect to $\mathcal{I}$ and $\mathcal{O}$.

*This is important when $S$ involves iteration or recursion.*


###Theorem 1

1. If $\vdash \mathcal{I} \Rightarrow \mathcal{J}$ and $\{\mathcal{J}\}S\{\mathcal{O}\}$ is partially verified, then $\{\mathcal{I}\}S\{\mathcal{O}\}$ is partially verified.
2. If $\{\mathcal{I}\}S\{\mathcal{J}\}$ is partially verified and $\vdash \mathcal{J} \Rightarrow \mathcal{O}$, then $\{\mathcal{I}\}S\{\mathcal{O}\}$ is partially verified.

This can be abbreviated to:

$$\frac{ \mathcal{I} \Rightarrow \mathcal{J} , \{\mathcal{J}\}S\{\mathcal{O}\} }{ \{\mathcal{I}\}S\{\mathcal{O}\} }$$

and

$$\frac{ \{\mathcal{I}\}S\{\mathcal{J}\}, \mathcal{J} \Rightarrow \mathcal{O} }{ \{\mathcal{I}\}S\{\mathcal{O}\} }$$

##Assignment
The notation $S(b/a)$ means the same sentence as $S$ but with all instances of $a$ replaced by $b$.

$$\frac{ \mathcal{I} \Rightarrow \mathcal{O}(t/x) }{ \{\mathcal{I}\}\mathtt{x=t;}\{\mathcal{O}\} }$$

###Example

$$\{a > 0\} \mathtt{x = a - 1;} \{ x = a - 1 \land x \ge 0\}$$

$$\mathcal{O} = \{x = a - 1 \land x \ge 0\}$$

$$\mathcal{O}(a-1/x) = \{a - 1 = a - 1 \land a - 1 \ge 0\}$$

$$ a > 0 \Rightarrow a - 1 = a - 1 \land a - 1 \ge 0$$

$$\therefore \; a > 0 \Rightarrow \mathcal{O}(a-1/x)$$


##Statement Sequences
For a sequence of statements $S_1;S_2;\dots;S_n$, there is the rule:

$$\frac{ \{\mathcal{I}\}S_1\{\mathcal{J}_1\}, \{\mathcal{J}_1\}S_2\{\mathcal{J}_2\},\dots,\{\mathcal{J}_n\}S_n\{\mathcal{O}\} }{ \{\mathcal{I}\}S_1;S_2;\dots;S_n\{\mathcal{O}\} }$$


##Conditional Statements

$$\frac{ \{\mathcal{I} \land B\}S_1\{\mathcal{O}\}, \{\mathcal{I} \land \neg B\}S_2\{\mathcal{O}\} }{ \{\mathcal{I} \mathtt{ if(B) } S_1 \mathtt{ else } S_2 \{\mathcal{O}\} }$$

Under the assumption $B$ has no side effects.

If there is no `else` statement then:


$$\frac{ \{\mathcal{I} \land B\}S\{\mathcal{O}\}, \mathcal{I} \land \neg B \Rightarrow \mathcal{O} }{ \{\mathcal{I} \mathtt{ if(B) } S \{\mathcal{O}\} }$$

Again assuming $B$ has no side effects.


##Iterations

The while loop can be specified as follows:

$$\frac{ \{\mathcal{I} \land B\} S \{\mathcal{I}\} }{ \{\mathcal{I}\} \mathtt{ while(B) } S(\mathcal{I} \land \neg B) }$$

Assuming $B$ has no side effects.

It is useful to introduce the idea of a **loop invariant**; a formula ($\mathcal{L}$) that remains true after each iteration of the loop, leading to the following rule:

$$\frac{ \mathcal{I} \Rightarrow \mathcal{L}, \{\mathcal{L} \land  B\}S\{\mathcal{L}\}, \mathcal{L} \land \neg B \Rightarrow \mathcal{O} }{ \{\mathcal{I}\}\texttt{ while(B) } S \{\mathcal{O}\} }$$
## Other Specification Methods

Software developers aren't going to use full-blown formal methods *except* where the cost of doing so justifies doing so (safety- and mission- critical systems). The complete use of mathematics is not justifiable in most cases.

There are some techniques to check a piece of code can be proved mathematically without too much effort without the heavy use of maths. This may help to avoid a lot of problems seen in code today.


### Deficiencies of VDM

VDM SL contains limited constructs for modularisation. Difficult to split a large specification into modules.

No support for palletisation and concurrency.

Must implement in a language which has also been formally specified.

RAISE (Rigorous Approach to Industrial Software Engineering) and others have tried to overcome some of the deficiencies of VDM.
## Worksheet 1

##Question 1
Show, by constructing the appropriate truth tables, that:

###1.a
$$\neg P,P \lor Q \models Q$$

 $P$   $Q$   $\neg P$   $P \lor Q$   $Q$
----- ----- ---------- ------------ -----
T     T     F          T            T
T     F     F          T            F
F     T     T          T            T
F     F     T          F            F


###1.b
$$P \land Q \models P \lor Q$$

 $P$   $Q$   $P \land Q$   $P \lor Q$
----- ----- ------------- ------------
T     T     T             T
T     F     F             T
F     T     F             T
F     F     F             F


###1.c
$$P \Rightarrow Q, Q \Rightarrow R \models P \Rightarrow R$$


 $P$   $Q$   $R$   $P \Rightarrow Q$   $Q \Rightarrow R$   $P \Rightarrow R$
----- ----- ----- ------------------- ------------------- -------------------
T     T     T     T                   T                   T
T     T     F     T                   F                   F
T     F     T     F                   T                   T
T     F     F     F                   T                   F
F     T     T     T                   T                   T
F     T     F     T                   F                   T
F     F     T     T                   T                   T
F     F     F     T                   T                   T


##Question 2
Show, by constructing the appropriate truth tables, that:

###2.a
$$\models (A \land B) \Leftrightarrow (\neg(\neg A \lor \neg B))$$

|c|c||c|c||c|

$A$ & $B$ & $A \land B$ & $(\neg(\neg A \lor \neg B))$ &
$A \land B \equiv \neg(\neg A \lor \neg B)$\
T & T & T & T & T\
T & F & F & F & T\
F & T & F & F & T\
F & F & F & F & T\


###2.b
$$\models (A \Rightarrow B) \Leftrightarrow (\neg A \lor B)$$

|c|c||c|c||c|

$A$ & $B$ & $A \Rightarrow B$ & $\neg A \lor B$ &
$A \Rightarrow B \equiv \neg A \lor B$\
T & T & T & T & T\
T & F & F & F & T\
F & T & T & T & T\
F & F & T & T & T\


###2.c
$$\models (A \Leftrightarrow B) \Leftrightarrow ((A \Rightarrow B) \land (B \Rightarrow A))$$

|c|c||c|c|c|c||c|

$A$ & $B$ & $A \Leftrightarrow B$ & $A \Rightarrow B$ &
$B \Rightarrow A$ & $(A \Rightarrow B) \land (B \Rightarrow A)$ &
$A \Leftrightarrow B \equiv (A \Rightarrow B) \land (B \Rightarrow A)$\
T & T & T & T & T & T & T\
T & F & F & F & T & F & T\
F & T & F & T & F & F & T\
F & F & T & T & T & T & T\

Using the results above, deduce than any proposition is logically
equivalent to one written using only the operators $\neg$ and $\lor$.

---

First, we know:

$$A \land B \equiv \neg(\neg A \lor \neg B)$$

And:

$$A \Rightarrow B \equiv \neg A \lor B$$

And:

$$A \Leftrightarrow B \equiv (A \Rightarrow B) \land (B \Rightarrow B)$$

Then using this, we can deduce:

$$A \Leftrightarrow B \equiv (\neg A \lor B) \land (A \lor \neg B)$$

Substituting out the $\land$:

$$A \Leftrightarrow B &\equiv \neg(\neg(\neg A \lor B) \land \neg(A \lor \neg B))\end$$

Define the operator $|$ (*nand*) by the truth table:

|c|c||c|

$A$ & $B$ & $A|B$\
T & T & F\
T & F & T\
F & T & T\
F & F & T\

Show, by constructing the appropriate truth tables that:

$$\models (\neg A) \Leftrightarrow (A | A)$$

|c||c|c||c|

$A$ & $\neg A$ & $A | A$ & $\neg A \equiv A|A$\
T & F & F & T\
F & T & T & T\

$$\models (A \lor B) \Leftrightarrow ((A|A)|(B|B))$$

|c|c||c|c||c|

$A$ & $B$ & $A \lor B$ & $(A|A)|(B|B)$ & $A \lor B \equiv (A|A)|(B|B)$\
T & T & T & T & T\
T & F & T & T & T\
F & T & T & T & T\
F & F & F & F & T\


###???

Using Q2 and these results, deduce that any proposition is logically
equivalent to one written using only the operator $|$.


We know:

$$\neg A \equiv A | A$$

And:

$$A \lor B \equiv (A|A)|(B|B)$$

And as we have already deduced that any proposition can be written using $\neg$ and $\lor$, we can just substitute in the above identities to replace both these operators in and proposition.

$$A \land B \equiv \neg(\neg A \lor \neg B)$$

$$\equiv \neg(\neg(A|A) | \neg(B|B))$$

Substitute $A|A$ for $\neg A$ to cancel out the double negatives.

$$\equiv \neg(A | B)$$

Therefore:

$$A \land B \equiv (A|B)|(A|B)$$

And:

$$A \lor \neg B \lor C \equiv ((A|A)|(\neg B|\neg B)) \lor C$$

$$\equiv ((A|A)|B) \lor C$$

$$\equiv ((A|A)|B)|(A|A)|B)|(C|C)$$

Prove the following:

$$\neg \neg P, P\Rightarrow Q \vdash P \land Q$$

  --- ------------------- ----------------------------------
  1   $\neg\neg P$        premise
  2   $P \Rightarrow Q$   premise
  3   $P$                 1 by $\neg$-Elimination
  4   $Q$                 3,2 by $\Rightarrow$-Elimination
  5   $P \land Q$         3,4 by $\land$-Introduction
  --- ------------------- ----------------------------------

Q.E.D.

$$P, P \Leftrightarrow Q \vdash Q \lor R$$

  --- ----------------------- ------------------------------------
  1   $P$                     premise
  2   $P \Leftrightarrow Q$   premise
  3   $P \Rightarrow Q$       2 by $\Leftrightarrow$-Elimination
  4   $Q$                     1,3 by $\Rightarrow$-Elimination
  5   $Q \lor R$              4 by $\lor$-Introduction
  --- ----------------------- ------------------------------------

Q.E.D.

$$P \land Q, P \Rightarrow S, Q \Rightarrow T \vdash S \land T$$

  --- ------------------- ----------------------------------
  1   $P \land Q$         premise
  2   $P \Rightarrow S$   premise
  3   $Q \Rightarrow T$   premise
  4   $P$                 1 by $\land$-Elimination
  5   $Q$                 1 by $\land$-Elimination
  6   $S$                 2,4 by $\Rightarrow$-Elimination
  7   $T$                 3,5 by $\Rightarrow$-Elimination
  8   $S \land T$         6,7 by $\land$-Introduction
  --- ------------------- ----------------------------------

Q.E.D.
